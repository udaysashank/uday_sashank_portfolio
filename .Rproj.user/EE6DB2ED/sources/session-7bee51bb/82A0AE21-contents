---
title: "TidyTuesday: Retail Sales data analysis with Plotly in R"
date: 01-2-2023 
author: Uday Sashank Kanapala 
categories: [code, analysis, visualization, plotly]
image: "b.jpg"
---

In this TidyTuesday analysis, I explored retail sales data using R and leveraged the power of Plotly for interactive visualizations. The dataset, likely sourced from the TidyTuesday project, was loaded and examined to gain insights into retail trends. Plotly, a dynamic plotting library, was employed to create engaging and interactive charts, allowing for a deeper understanding of sales patterns, seasonality, or any trends within the retail sector. This approach not only facilitates exploration but also enhances the communicative aspect of data findings through visually appealing and interactive plots.

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(plotly)
library(gplots)
library(caret)
library(randomForest)
library(e1071)

# Load the Walmart data
Walmart <-  read.csv("C:/Users/P/Downloads/Walmart.csv")

# Data Cleanup
# Convert Date column to Date format
Walmart$Date <- as.Date(Walmart$Date)

# Feature Engineering
# Extract Year, Month, and Day from Date
Walmart$Year <- format(Walmart$Date, "%Y")
Walmart$Month <- format(Walmart$Date, "%m")
Walmart$Day <- format(Walmart$Date, "%d")

# Exploratory Data Analysis (EDA)

# Display the first few rows of the dataset
head(Walmart)

# Summary statistics
summary(Walmart)

# Distribution plot for Weekly Sales
ggplot(Walmart, aes(x = Weekly_Sales)) +
  geom_histogram(binwidth = 5000, fill = "#4CAF50", color = "#2E7D32", alpha = 0.7) +
  labs(title = "Distribution of Weekly Sales",
       x = "Weekly Sales", y = "Frequency") +
  theme_minimal()

# Boxplot for Weekly Sales by Store
ggplot(Walmart, aes(x = Store, y = Weekly_Sales)) +
  geom_boxplot(fill = "#FF4081", alpha = 0.7) +
  labs(title = "Boxplot of Weekly Sales by Store",
       x = "Store", y = "Weekly Sales") +
  theme_minimal()

# Scatter plot for Weekly Sales and Temperature
ggplot(Walmart, aes(x = Temperature, y = Weekly_Sales)) +
  geom_point(color = "#1976D2", alpha = 0.7) +
  labs(title = "Scatter Plot of Weekly Sales vs Temperature",
       x = "Temperature", y = "Weekly Sales") +
  theme_minimal()

# Quartile plot
quartile_data <- Walmart %>%
  group_by(Date) %>%
  summarise(Q1 = quantile(Weekly_Sales, 0.25),
            Q3 = quantile(Weekly_Sales, 0.75))

ggplot(quartile_data, aes(x = Date)) +
  geom_line(aes(y = Q1), color = "#673AB7", linetype = "dashed") +
  geom_line(aes(y = Q3), color = "#673AB7", linetype = "dashed") +
  labs(title = "Quartile Sales Over Time",
       x = "Date", y = "Weekly Sales",
       color = "Quartile") +
  theme_minimal()

# Model Evaluation
# Split the data into training and testing sets
set.seed(123)
train_indices <- createDataPartition(Walmart$Weekly_Sales, p = 0.7, list = FALSE)
trainData <- Walmart[train_indices, ]
testData <- Walmart[-train_indices, ]

# Evaluate the linear regression model
lm_model <- lm(Weekly_Sales ~ Temperature + Fuel_Price + CPI + Unemployment + Holiday_Flag, data = trainData)
lm_predictions <- predict(lm_model, newdata = testData)
lm_r2 <- cor(lm_predictions, testData$Weekly_Sales)^2
lm_rmse <- sqrt(mean((lm_predictions - testData$Weekly_Sales)^2))

# Evaluate the random forest model
rf_model <- randomForest(Weekly_Sales ~ Temperature + Fuel_Price + CPI + Unemployment + Holiday_Flag, data = trainData)
rf_predictions <- predict(rf_model, newdata = testData)
rf_r2 <- cor(rf_predictions, testData$Weekly_Sales)^2
rf_rmse <- sqrt(mean((rf_predictions - testData$Weekly_Sales)^2))

cat("Linear Regression Model:\n")
cat("R-squared:", lm_r2, "\n")
cat("RMSE:", lm_rmse, "\n\n")

cat("Random Forest Model:\n")
cat("R-squared:", rf_r2, "\n")
cat("RMSE:", rf_rmse, "\n")

```

The linear regression model achieved a relatively low R-squared value of 0.0155, indicating that the model explains only a small proportion of the variance in the weekly sales. Additionally, the Root Mean Squared Error (RMSE) of 553,801.7 suggests a significant deviation between the predicted and actual sales values, emphasizing the limitations of the linear model in capturing the underlying patterns in the data.

On the other hand, the Random Forest model exhibited better performance with a higher R-squared value of 0.1402, signifying a greater ability to explain variability in weekly sales. The lower RMSE of 521,092.6 further supports the Random Forest model as a more accurate predictor compared to the linear regression model. This suggests that the Random Forest algorithm, which leverages ensemble learning and decision trees, provides a more robust and flexible approach for capturing the complex relationships within the Walmart sales data set.
